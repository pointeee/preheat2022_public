{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astropy.io import fits\n",
    "from astropy.io import ascii\n",
    "from astropy.table import Table\n",
    "from astropy.cosmology import FlatLambdaCDM, z_at_value\n",
    "\n",
    "from field_util import Field, CartCoord\n",
    "from FGPA_to_skewers import Mock_skewer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(114514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../Data/'\n",
    "plot_path = '../Plot/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo = FlatLambdaCDM(H0=100* u.km / u.s / u.Mpc, Om0=0.315) # Metin original\n",
    "mycoord = CartCoord(150.14205192829834, 2.224237689411875, cosmo) # Used in Cosmic Birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract metadata\n",
    "\n",
    "# CLAMATO galaxies\n",
    "clamato_gal = '../Data/CLAMATO/list_tomo_input_2020_mod.txt'\n",
    "clm_gal_list = pd.read_csv(clamato_gal, sep = '\\t', header = 0)\n",
    "\n",
    "# CLAMATO full catalog\n",
    "clamato_full = '../Data/CLAMATO/cl2020_valueadded_release_20200602_mod.txt'\n",
    "clm_full_list = pd.read_csv(clamato_full)\n",
    "\n",
    "clm_gal_with_SN = pd.merge(clm_gal_list, clm_full_list, left_on='TomoID', right_on='TOMO_ID')\n",
    "# - S/N_1: Estimated Lya-forest S/N at 2.05<z<2.15, -9.0 denotes no estimate\n",
    "# - S/N_2: Estimated Lya-forest S/N at 2.15<z<2.35, -9.0 denotes no estimate\n",
    "# - S/N_2: Estimated Lya-forest S/N at 2.35<z<2.55, -9.0 denotes no estimate\n",
    "clm_gal_short = clm_gal_with_SN[['TomoID', 'S/N_1', 'S/N_2', 'S/N_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAMATO pixel\n",
    "clamato_pixel = data_path+'CLAMATO/pixel_data_dr2.bin'\n",
    "x_0, y_0, z_0 = mycoord.orig_to_box(150.14205192829834, 2.224237689411875, 2.05)\n",
    "with open(clamato_pixel,'r') as f:\n",
    "    npix = np.fromfile(f, dtype=np.int32, count=1)[0]\n",
    "    f.seek(4)\n",
    "    pixel_data = np.fromfile(f,dtype=np.float64).reshape(npix,5)\n",
    "\n",
    "x_new, y_new, z_new = mycoord.orig_to_box(clm_gal_list['ra'], clm_gal_list['dec'], 2.30)\n",
    "coord_new = np.zeros([pixel_data.shape[0], 3])\n",
    "coord_new[:, 0] = pixel_data[:, 2] + x_0.value\n",
    "for i, gal in enumerate(clm_gal_list.iloc):\n",
    "    coord_new[int(gal['i_start']):int(gal['i_end'])+1,1] = y_new[i].value\n",
    "    coord_new[int(gal['i_start']):int(gal['i_end'])+1,2] = z_new[i].value\n",
    "\n",
    "tomo_id = np.zeros([pixel_data.shape[0], 1], dtype=int)\n",
    "for i, gal in enumerate(clm_gal_list.iloc):\n",
    "    tomo_id[int(gal['i_start']):int(gal['i_end'])+1, 0] = gal['TomoID']\n",
    "\n",
    "pixel_data = np.hstack([tomo_id, pixel_data, coord_new])\n",
    "pixel_data_df = pd.DataFrame(pixel_data, columns = ['tomo_id', 'x', 'y', 'z', 'sigma_f', 'delta_f', \n",
    "                                                    'x_new', 'y_new', 'z_new'])\n",
    "pixel_data_df['tomo_id'] = (pixel_data_df['tomo_id']).astype(int)\n",
    "N_pix = len(pixel_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge SNR data from CLAMATO\n",
    "clm_red_list = clm_full_list[['TOMO_ID', 'ZSPEC']]\n",
    "pixel_data_df = pd.merge(pixel_data_df, clm_red_list, left_on = 'tomo_id', right_on = 'TOMO_ID')\n",
    "del pixel_data_df['TOMO_ID']\n",
    "\n",
    "def z_from_dist(distance, cosmo):\n",
    "    dummyred = np.linspace(0.,10.,10000)\n",
    "    dummydist = cosmo.comoving_distance(dummyred)\n",
    "    res = np.interp(distance,dummydist,dummyred)\n",
    "    return (res)\n",
    "pixel_data_df['red'] = z_from_dist(pixel_data_df['x_new']*u.Mpc, cosmo)\n",
    "\n",
    "pixel_data_temp = pd.merge(pixel_data_df, clm_gal_short, left_on='tomo_id', right_on='TomoID')\n",
    "SNR = ((pixel_data_temp['red'] < 2.15) * (pixel_data_temp['red'] > 2.05) * pixel_data_temp['S/N_1'] +\n",
    "       (pixel_data_temp['red'] < 2.35) * (pixel_data_temp['red'] > 2.15) * pixel_data_temp['S/N_2'] +\n",
    "       (pixel_data_temp['red'] < 2.55) * (pixel_data_temp['red'] > 2.35) * pixel_data_temp['S/N_3'])\n",
    "SNR[SNR<=0] = np.nan\n",
    "pixel_data_temp['S/N'] = SNR\n",
    "pixel_data_temp = pixel_data_temp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tau file\n",
    "tau_list = [fn for fn in os.listdir(data_path+'lores_tau/') if fn[-7:]=='tau.npy']\n",
    "fn = tau_list[0]\n",
    "\n",
    "# from this part we will make a loop\n",
    "# load tau map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate mock skewers as dachshund input\n",
    "np.random.seed(1919)\n",
    "\n",
    "for fn in tau_list:\n",
    "    for j in range(20):\n",
    "        fn_new = '_'.join(fn.split('_')[1:3])\n",
    "        tau_data = np.load(data_path+'lores_tau/'+fn)[:,::-1,:]\n",
    "        # convert to transmission\n",
    "        tran_data = np.exp(-tau_data)\n",
    "        delta_F = np.exp(-tau_data) / np.exp(-tau_data).mean() - 1\n",
    "        field_trans =  Field(3550.*u.Mpc, -50.*u.Mpc, -50.*u.Mpc, 2*u.Mpc, tran_data)\n",
    "        _ = field_trans.smooth(2*u.Mpc)\n",
    "        # raw data w/o noise\n",
    "        res = field_trans.field_eval(np.array(pixel_data_temp['x_new'])*u.Mpc, \n",
    "                                     np.array(pixel_data_temp['y_new'])*u.Mpc,\n",
    "                                     np.array(pixel_data_temp['z_new'])*u.Mpc)\n",
    "        pixel_data_temp['F_raw'] = res\n",
    "\n",
    "        # turbulate transmission with a gaussian\n",
    "        # pixel_data_temp['F_obs'] = pixel_data_temp['F_raw']\n",
    "        pixel_data_temp['delta_F_sim'] = pixel_data_temp['F_raw'] / pixel_data_temp['F_raw'].mean() - 1\n",
    "        pixel_data_temp['sigma_F_sim'] = (1. / pixel_data_temp['S/N'] + 0.1) / pixel_data_temp['F_raw'].mean()\n",
    "\n",
    "        # add noise based on SNR\n",
    "        pixel_data_temp['delta_F_rec'] = pixel_data_temp['delta_F_sim'] + np.random.normal(scale=pixel_data_temp['sigma_F_sim'])\n",
    "\n",
    "        # export the result\n",
    "        pix_sim = np.array(pixel_data_temp[['x', 'y', 'z', 'sigma_F_sim', 'delta_F_rec']])\n",
    "        pix_sim[:,3][np.isnan(pix_sim[:,3])] = 10 # large var\n",
    "        pix_sim[:,4][np.isnan(pix_sim[:,4])] = 0 # null value\n",
    "\n",
    "        pixel_data_temp = pixel_data_temp.dropna() # some pixels go beyond the red range\n",
    "        N_pix = len(pixel_data_temp)\n",
    "\n",
    "        # pix_sim.tofile(data_path+\"/mock_skewers_ex/pixel_data_{}.bin\".format(fn[:-14]))\n",
    "        pix_sim.tofile(data_path+\"/mock_skewers_ex/pixel_data_{}_{}_true_SNR.bin\".format(fn_new, j))\n",
    "        pix_sim.tofile(data_path+\"/mock_skewers_hires/pixel_data_{}_{}_true_SNR.bin\".format(fn_new, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13 (default, Mar 28 2022, 06:13:39) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c5d1a8b75d58d5e3ad3ca5e74b657d0adecc3dcb1e754f69c7a60102c99952b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
